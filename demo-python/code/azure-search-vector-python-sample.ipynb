{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector search in Python (Azure AI Search)\n",
    "This code demonstrates how to use Azure AI Search by using the push API to insert vectors into your search index.\n",
    "\n",
    "Use this notebook to generate text embeddings using Azure OpenAI, insert those embeddings into a vector store in Azure AI Search, and perform a wide variety of vector search queries, including vector searches with metadata filtering and hybrid (text + vectors) search. The code uses Azure OpenAI to generate embeddings for title and content fields. You'll need access to Azure OpenAI to run this demo.\n",
    "\n",
    "The sample data is a `data/text-sample.json` file containing 108 descriptions of various Azure services. The descriptions are short, which makes data chunking unnecessary.\n",
    "\n",
    "The output is a combination of human-readable text and embeddings that can be pushed into a search index.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    "\n",
    "+ Azure AI Search, any tier, but we recommend Basic or higher for this workload. [Enable semantic ranker](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable) if you want to run a hybrid query with semantic ranking.\n",
    "\n",
    "+ A deployment of the `text-embedding-ada-002` embedding model in your Azure OpenAI service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r azure-search-vector-python-sample-requirements.txt --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]\n",
    "embedding_model_name = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\"]\n",
    "azure_openai_api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure AI Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import json\n",
    "\n",
    "openai_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    azure_ad_token_provider=token_provider if not azure_openai_key else None\n",
    ")\n",
    "\n",
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "# Read the text-sample.json\n",
    "path = os.path.join('..', 'data', 'text-sample.json')\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "titles = [item['title'] for item in input_data]\n",
    "content = [item['content'] for item in input_data]\n",
    "title_response = client.embeddings.create(input=titles, model=embedding_model_name)\n",
    "title_embeddings = [item.embedding for item in title_response.data]\n",
    "content_response = client.embeddings.create(input=content, model=embedding_model_name)\n",
    "content_embeddings = [item.embedding for item in content_response.data]\n",
    "\n",
    "# Generate embeddings for title and content fields\n",
    "for i, item in enumerate(input_data):\n",
    "    title = item['title']\n",
    "    content = item['content']\n",
    "    item['titleVector'] = title_embeddings[i]\n",
    "    item['contentVector'] = content_embeddings[i]\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "output_path = os.path.join('..', 'output', 'docVectors.json')\n",
    "output_directory = os.path.dirname(output_path)\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your search index\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Create the search index with the semantic settings\u001b[39;00m\n\u001b[0;32m     63\u001b[0m index \u001b[38;5;241m=\u001b[39m SearchIndex(name\u001b[38;5;241m=\u001b[39mindex_name, fields\u001b[38;5;241m=\u001b[39mfields,\n\u001b[0;32m     64\u001b[0m                     vector_search\u001b[38;5;241m=\u001b[39mvector_search, semantic_search\u001b[38;5;241m=\u001b[39msemantic_search)\n\u001b[1;32m---> 65\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mindex_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m created\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\search\\documents\\indexes\\_search_index_client.py:269\u001b[0m, in \u001b[0;36mSearchIndexClient.create_or_update_index\u001b[1;34m(self, index, allow_index_downtime, match_condition, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(access_condition)\n\u001b[0;32m    268\u001b[0m patched_index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39m_to_generated()  \u001b[38;5;66;03m# pylint:disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatched_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_index_downtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_index_downtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn=representation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SearchIndex\u001b[38;5;241m.\u001b[39m_from_generated(result)\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\search\\documents\\indexes\\_generated\\operations\\_indexes_operations.py:706\u001b[0m, in \u001b[0;36mIndexesOperations.create_or_update\u001b[1;34m(self, index_name, prefer, index, allow_index_downtime, if_match, if_none_match, request_options, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m _request\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mformat_url(_request\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpath_format_arguments)\n\u001b[0;32m    705\u001b[0m _stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m pipeline_response: PipelineResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m201\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:230\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m pipeline_request: PipelineRequest[HTTPRequestType] \u001b[38;5;241m=\u001b[39m PipelineRequest(request, context)\n\u001b[0;32m    229\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport)\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfirst_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "    \u001b[1;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 86 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py:197\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    195\u001b[0m original_domain \u001b[38;5;241m=\u001b[39m get_domain(request\u001b[38;5;241m.\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl) \u001b[38;5;28;01mif\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[1;32m--> 197\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     redirect_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_redirect_location(response)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m redirect_location \u001b[38;5;129;01mand\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py:531\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[1;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_retry(retry_settings, response):\n\u001b[0;32m    533\u001b[0m         retry_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincrement(retry_settings, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py:124\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: PipelineRequest[HTTPRequestType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PipelineResponse[HTTPRequestType, HTTPResponseType]:\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Authorize request with a bearer token and send it to the next policy\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    :param request: The pipeline request object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    :rtype: ~azure.core.pipeline.PipelineResponse\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n",
      "File \u001b[1;32mc:\\Users\\heidist\\azure-search-vector-samples\\demo-python\\.venv\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py:99\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.on_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credential\u001b[38;5;241m.\u001b[39mget_token(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scopes, enable_cae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_cae)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_credential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scopes)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_headers(request\u001b[38;5;241m.\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mheaders, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token\u001b[38;5;241m.\u001b[39mtoken)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_token'"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex\n",
    ")\n",
    "\n",
    "\n",
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=endpoint, credential=credential)\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_search=semantic_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "\n",
    "# Upload some documents to the index\n",
    "output_path = os.path.join('..', 'output', 'docVectors.json')\n",
    "output_directory = os.path.dirname(output_path)\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "with open(output_path, 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are indexing a very large number of documents, you can use the `SearchIndexingBufferedSender` which is an optimized way to automatically index the docs as it will handle the batching for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "# Upload some documents to the index  \n",
    "with open(output_path, 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "  \n",
    "# Use SearchIndexingBufferedSender to upload the documents in batches optimized for indexing  \n",
    "with SearchIndexingBufferedSender(  \n",
    "    endpoint=endpoint,  \n",
    "    index_name=index_name,  \n",
    "    credential=credential,  \n",
    ") as batch_client:  \n",
    "    # Add upload actions for all documents  \n",
    "    batch_client.upload_documents(documents=documents)  \n",
    "print(f\"Uploaded {len(documents)} documents in total\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows a pure vector search to demonstrate OpenAI's text-embedding-ada-002 multilingual capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search multi-lingual (e.g 'tools for software development' in Dutch)  \n",
    "query = \"tools voor softwareontwikkeling\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an Exhaustive KNN exact nearest neighbor search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how you can exhaustively search your vector index regardless of what index you have, HNSW or ExhaustiveKNN. You can use this to calculate the ground-truth values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Cross-Field Vector Search\n",
    "\n",
    "This example shows a cross-field vector search that allows you to query multiple vector fields at the same time. Note, ensure that the same embedding model was used for the vector fields you decide to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector, titleVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Multi-Vector Search\n",
    "\n",
    "This example shows a cross-field vector search that allows you to query multiple vector fields at the same time by passing in multiple query vectors. Note, in this case, you can pass in query vectors from two different embedding models to the corresponding vector fields in your index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "\n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query_1 = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"titleVector\")\n",
    "vector_query_2 = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries=[vector_query_1, vector_query_2],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Pure Vector Search with a filter\n",
    "This example shows how to apply filters on your index. Note, that you can choose whether you want to use Pre-Filtering (default) or Post-Filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorFilterMode\n",
    "\n",
    "# Pure Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    vector_filter_mode=VectorFilterMode.PRE_FILTER,\n",
    "    filter=\"category eq 'Developer Tools'\",\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")\n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "query = \"scalable storage solution\"  \n",
    "  \n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=3\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Semantic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType\n",
    "\n",
    "# Semantic Hybrid Search\n",
    "query = \"what is azure sarch?\"\n",
    "\n",
    "embedding = client.embeddings.create(input=query, model=embedding_model_name).data[0].embedding\n",
    "vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=3, fields=\"contentVector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=QueryType.SEMANTIC, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
